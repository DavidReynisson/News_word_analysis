{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d13f73e",
   "metadata": {},
   "source": [
    "# Step 5: Predicting engagement based on sentiments (NO LONGER ACTIVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f49580",
   "metadata": {},
   "source": [
    "This machine learning prediction is no longer in use. I had to scale back the scope of my research after my research partner quit the course at the last minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c5bc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandas import Series\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d52ed0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dyker Heights murder suspect allegedly killed ...</td>\n",
       "      <td>112</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.9652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asian man stabbed in back in Chinatown, suspec...</td>\n",
       "      <td>17577</td>\n",
       "      <td>1061</td>\n",
       "      <td>-0.9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Satanic' neo-Nazi terrorist arrested at Luton...</td>\n",
       "      <td>281</td>\n",
       "      <td>108</td>\n",
       "      <td>-0.9451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man hires two to kill rape victim, pair kills ...</td>\n",
       "      <td>7735</td>\n",
       "      <td>723</td>\n",
       "      <td>-0.9432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mom helped teen murder suspects flee state; 5 ...</td>\n",
       "      <td>167</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>West Virginia police giving out gift cards rat...</td>\n",
       "      <td>258</td>\n",
       "      <td>101</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>Friends share Powerball jackpot win, keeping 1...</td>\n",
       "      <td>1140</td>\n",
       "      <td>82</td>\n",
       "      <td>0.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>Trump to award trio of golfers Medal of Freedom</td>\n",
       "      <td>1152</td>\n",
       "      <td>269</td>\n",
       "      <td>0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>Two French Navy FREMM Frigates Won a U.S. Navy...</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>Global Warming Breakthrough: Australian 'super...</td>\n",
       "      <td>16477</td>\n",
       "      <td>873</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6060 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  score  num_comments  \\\n",
       "0     Dyker Heights murder suspect allegedly killed ...    112            22   \n",
       "1     Asian man stabbed in back in Chinatown, suspec...  17577          1061   \n",
       "2     'Satanic' neo-Nazi terrorist arrested at Luton...    281           108   \n",
       "3     Man hires two to kill rape victim, pair kills ...   7735           723   \n",
       "4     Mom helped teen murder suspects flee state; 5 ...    167            17   \n",
       "...                                                 ...    ...           ...   \n",
       "6055  West Virginia police giving out gift cards rat...    258           101   \n",
       "6056  Friends share Powerball jackpot win, keeping 1...   1140            82   \n",
       "6057    Trump to award trio of golfers Medal of Freedom   1152           269   \n",
       "6058  Two French Navy FREMM Frigates Won a U.S. Navy...     99             5   \n",
       "6059  Global Warming Breakthrough: Australian 'super...  16477           873   \n",
       "\n",
       "      sentiment  \n",
       "0       -0.9652  \n",
       "1       -0.9571  \n",
       "2       -0.9451  \n",
       "3       -0.9432  \n",
       "4       -0.9393  \n",
       "...         ...  \n",
       "6055     0.8834  \n",
       "6056     0.8860  \n",
       "6057     0.8957  \n",
       "6058     0.9062  \n",
       "6059     0.9100  \n",
       "\n",
       "[6060 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr_titles = pd.read_csv('mlr_titles.csv').drop(['Unnamed: 0'], axis=1)\n",
    "mlr_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ac29de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 \n",
    "# Define X and y\n",
    "X =  mlr_titles['sentiment'].values\n",
    "#X = mlr_titles['score'].values + mlr_titles['sentiment'].values \n",
    "y = mlr_titles['score'].values\n",
    "#Now we split the data into development and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=161193)\n",
    "#split development dataset into a training and validation dataset. For 10-fold cross-validation we have a test-size of 0.1\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=161193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2aff59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d61ae063",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(PolynomialFeatures(degree = 1), StandardScaler(), LinearRegression())\n",
    "\n",
    "pipe.fit(X_train.reshape(-1,1), y_train.reshape(-1,1)) # have to reshape so that we get 2D array\n",
    "y_pred = pipe.predict(X_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "495d0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda: 0.0001\n",
      "Validation MSE: 231389531.773\n"
     ]
    }
   ],
   "source": [
    "# prep\n",
    "perform = [] #store performance\n",
    "lambdas = np.logspace(-4, -4., 20) #grid of lambdas (hyperparameters)\n",
    "\n",
    "#for each lambda, fit model on training data, check performance on validation and store mse\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    pipe_lasso =  make_pipeline(PolynomialFeatures(), StandardScaler(), Lasso(alpha=lambda_, random_state=12465))\n",
    "    pipe_lasso.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
    "    y_pred = pipe_lasso.predict(X_val.reshape(-1, 1))\n",
    "    perform.append(mse(y_pred, y_val.reshape(-1, 1)))\n",
    "\n",
    "#create series with performance and find parameter with lowest MSE\n",
    "hyperparam_perform = pd.Series(perform, index=lambdas)\n",
    "optimal = hyperparam_perform.nsmallest(1)\n",
    "print('Optimal lambda:', optimal.index[0])\n",
    "print('Validation MSE: %.3f' % optimal.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "70f7cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda: 0.01\n",
      "Validation MSE: 231389581.334\n"
     ]
    }
   ],
   "source": [
    "# prep\n",
    "perform = [] #store performance\n",
    "lambdas = np.logspace(-2, -2., 50) #grid of initial lambdas (hyperparameters)\n",
    "\n",
    "#for each lambda, fit model on training data, check performance on validation and store mse\n",
    "for lambda_ in lambdas:\n",
    "    \n",
    "    pipe_lasso =  make_pipeline(PolynomialFeatures(), StandardScaler(), Lasso(alpha=lambda_, random_state=12465))\n",
    "    pipe_lasso.fit(X_train.reshape(-1, 1), y_train.reshape(-1, 1))\n",
    "    y_pred = pipe_lasso.predict(X_val.reshape(-1, 1))\n",
    "    perform.append(mse(y_pred, y_val.reshape(-1, 1)))\n",
    "\n",
    "#create series with performance and find parameter with lowest MSE\n",
    "hyperparam_perform = pd.Series(perform, index=lambdas)\n",
    "optimal = hyperparam_perform.nsmallest(1)\n",
    "print('Optimal lambda:', optimal.index[0])\n",
    "print('Validation MSE: %.3f' % optimal.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "871e8a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso (246011119.44931573, 2)\n"
     ]
    }
   ],
   "source": [
    "#Insert optimal lambda into new model:\n",
    "pipe_lasso = make_pipeline(PolynomialFeatures(), StandardScaler(), Lasso(alpha=optimal.index[0]))\n",
    "#Fit new model on all the development data to build best model\n",
    "pipe_lasso.fit(X_dev.reshape(-1, 1), y_dev.reshape(-1, 1))\n",
    "\n",
    "#give model performance\n",
    "print('Lasso', (mse(pipe_lasso.predict(X_test.reshape(-1, 1)),y_test.reshape(-1, 1)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f115f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe307e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
